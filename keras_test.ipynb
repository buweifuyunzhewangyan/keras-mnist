{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      " 5734400/11490434 [=============>................] - ETA: 2:03"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.layers import Dense,Flatten,Input,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#加载数据集\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "\n",
    "inputshape = (224,224)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, y_train = X_train[:1000], y_train[:1000]#训练集1000条\n",
    "X_test, y_test = X_test[:100], y_test[:100]#测试集100条\n",
    "\n",
    "#变换图像size\n",
    "X_train = [cv2.cvtColor(cv2.resize(i, inputshape), cv2.COLOR_GRAY2RGB)\n",
    "           for i in X_train]\n",
    "X_test = [cv2.cvtColor(cv2.resize(i, inputshape), cv2.COLOR_GRAY2RGB)\n",
    "           for i in X_test]\n",
    "X_train = np.concatenate([arr[np.newaxis] for arr in X_train]).astype('float32')\n",
    "X_test = np.concatenate([arr[np.newaxis] for arr in X_test]).astype('float32')\n",
    "\n",
    "#数据归一化处理\n",
    "X_train = preprocess_input(np.array(X_train))\n",
    "X_test = preprocess_input(np.array(X_test))\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Elane053\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1047: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Elane053\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2385: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Elane053\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1108: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 224, 224, 64)  1792        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 224, 224, 64)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 112, 112, 64)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 112, 112, 128) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 112, 112, 128) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 56, 56, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 56, 56, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 28, 28, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 28, 28, 512)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 14, 14, 512)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 14, 14, 512)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 7, 7, 512)     0           block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)        (None, 10)            27508514    block5_pool[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 42,223,202\n",
      "Trainable params: 42,223,202\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#搭建神经网络\n",
    "vgg_model = VGG16(include_top=False,weights='imagenet',input_shape=(224,224,3))\n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape=vgg_model.output_shape[1:]))\n",
    "#add_model.add(Dense(4096,activation='relu'))\n",
    "add_model.add(Dense(1096,activation='relu'))\n",
    "add_model.add(Dropout(0.5))\n",
    "add_model.add(Dense(10,activation='softmax'))\n",
    "model = Model(vgg_model.input,add_model(vgg_model.output))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "            metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 2506s - loss: 2.1050 - acc: 0.4000 - val_loss: 0.6301 - val_acc: 0.8400\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 2621s - loss: 0.5501 - acc: 0.8337 - val_loss: 0.2880 - val_acc: 0.9200\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 2685s - loss: 0.2428 - acc: 0.9325 - val_loss: 0.2508 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 2590s - loss: 0.1294 - acc: 0.9663 - val_loss: 0.1915 - val_acc: 0.9550\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 2586s - loss: 0.0786 - acc: 0.9712 - val_loss: 0.1851 - val_acc: 0.9550\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 2412s - loss: 0.0903 - acc: 0.9700 - val_loss: 0.2334 - val_acc: 0.9550\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 2409s - loss: 0.0734 - acc: 0.9688 - val_loss: 0.1931 - val_acc: 0.9500\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 2406s - loss: 0.0385 - acc: 0.9875 - val_loss: 0.1805 - val_acc: 0.9600\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 2407s - loss: 0.0295 - acc: 0.9888 - val_loss: 0.2691 - val_acc: 0.9500\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 2403s - loss: 0.0331 - acc: 0.9888 - val_loss: 0.2786 - val_acc: 0.9450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x288b6605630>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=30, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=30, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=True)\n",
    "\n",
    "#对label进行onehot编码\n",
    "y_train_ohe = to_categorical(y_train,num_classes=10)\n",
    "y_test_ohe = to_categorical(y_test,num_classes=10)\n",
    "\n",
    "batch_size = 16 # tune it\n",
    "epochs = 10 # increase it\n",
    "#train_datagen = train_datagen.flow(X_train, y_train_ohe, batch_size=batch_size)\n",
    "#test_datagen = test_datagen.flow(X_test,y_test_ohe,batch_size=batch_size)\n",
    "model.fit(X_train,y_train_ohe,batch_size=16,nb_epoch=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "(1000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "df = pd.read_csv('test.csv')\n",
    "a = np.array(df.loc[0:])\n",
    "a = np.expand_dims(a,axis=1)\n",
    "X_test = a.reshape((28000,28,28)).astype('float32')\n",
    "\n",
    "inputshape = (224,224)\n",
    "X_test = X_test[:1000]\n",
    "X_test = [cv2.cvtColor(cv2.resize(i, inputshape), cv2.COLOR_GRAY2RGB)\n",
    "           for i in X_test]\n",
    "print(123)\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "X_test = preprocess_input(X_test)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Elane053\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1047: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Elane053\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2385: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Elane053\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1108: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "<class 'numpy.ndarray'> (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "model = load_model('mnist.h5')\n",
    "y_pre = model.predict(X_test)\n",
    "print(type(y_pre),y_pre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
